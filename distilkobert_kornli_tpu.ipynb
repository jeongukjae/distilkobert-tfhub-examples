{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distilkobert-kornli-tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZlZ6FANsmQOhUq6Ujce1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongukjae/distilkobert-tfhub-examples/blob/main/distilkobert_kornli_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfiK_QExt6Tp"
      },
      "source": [
        "# Training DistilKoBERT on KorNLI dataset\n",
        "\n",
        "* kornli dataset: https://jeongukjae.github.io/tfds-korean/datasets/kornli.html\n",
        "* distilkobert\n",
        "    * encoder: https://tfhub.dev/jeongukjae/distilkobert_cased_L-3_H-768_A-12/1\n",
        "    * preprocessor: https://tfhub.dev/jeongukjae/distilkobert_cased_preprocess/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttTij8Wxunvj"
      },
      "source": [
        "## Install pacakges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYHYOh3tpX4q"
      },
      "source": [
        "!pip install -q \\\n",
        "    tensorflow-text \\\n",
        "    tfds-korean"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl-rCywwurVs"
      },
      "source": [
        "## Prepare environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWNDNIMNpe8v"
      },
      "source": [
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tfds_korean.kornli"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4Inyd4Op4DQ"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsyCvonGp2PG",
        "outputId": "053500b6-31f2-4e79-efd7-d23dea720a71"
      },
      "source": [
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "strategy = tf.distribute.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.0.67.138:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.0.67.138:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKvTiJAHuwJY"
      },
      "source": [
        "## Set up hyperparameters and build models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCVR5ggfpvi1"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 5\n",
        "WARMUP_RATE = 0.05"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO6kGKv6p6ay"
      },
      "source": [
        "def create_preprocessing_model():\n",
        "    preprocessor = hub.load(\"https://tfhub.dev/jeongukjae/distilkobert_cased_preprocess/1\")\n",
        "    tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "    bert_pack_inputs = hub.KerasLayer(preprocessor.bert_pack_inputs)\n",
        "\n",
        "    text_inputs = [\n",
        "        tf.keras.Input([], dtype=tf.string),\n",
        "        tf.keras.Input([], dtype=tf.string),\n",
        "    ]\n",
        "    tokens = [tokenize(item) for item in text_inputs]\n",
        "    model_inputs = bert_pack_inputs(tokens)\n",
        "    return tf.keras.Model(text_inputs, model_inputs)\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/distilkobert_cased_L-3_H-768_A-12/1\", trainable=True)\n",
        "    inputs = {\n",
        "        \"input_word_ids\": tf.keras.Input([None], dtype=tf.int32, name=\"input_word_ids\"),\n",
        "        \"input_mask\": tf.keras.Input([None], dtype=tf.int32, name=\"input_mask\"),\n",
        "    }\n",
        "    logit = encoder(inputs)['pooled_output']\n",
        "    logit = tf.keras.layers.Dropout(0.1)(logit)\n",
        "    pred = tf.keras.layers.Dense(3)(logit)\n",
        "    model = tf.keras.Model(inputs, pred)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2nLPye4p69g"
      },
      "source": [
        "class BertScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, rate, warmup_ratio, total_steps, name=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rate = rate\n",
        "        self.warmup_ratio = warmup_ratio\n",
        "        self.total_steps = float(total_steps)\n",
        "        self.warmup_steps = warmup_ratio * total_steps\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, step):\n",
        "        with tf.name_scope(\"BertScheduler\"):\n",
        "            total_steps = tf.convert_to_tensor(self.total_steps, name=\"total_steps\")\n",
        "            warmup_steps = tf.convert_to_tensor(self.warmup_steps, name=\"warmup_steps\")\n",
        "\n",
        "            current_step = step + 1.0\n",
        "\n",
        "            return self.rate * tf.cond(\n",
        "                current_step < warmup_steps,\n",
        "                lambda: self.warmup(current_step, warmup_steps),\n",
        "                lambda: self.decay(current_step, total_steps, warmup_steps),\n",
        "            )\n",
        "\n",
        "    @tf.function\n",
        "    def warmup(self, step, warmup_steps):\n",
        "        return step / tf.math.maximum(tf.constant(1.0), warmup_steps)\n",
        "\n",
        "    @tf.function\n",
        "    def decay(self, step, total_steps, warmup_steps):\n",
        "        return tf.math.maximum(\n",
        "            tf.constant(0.0), (total_steps - step) / tf.math.maximum(tf.constant(1.0), total_steps - warmup_steps)\n",
        "        )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxUBTHjwu52M"
      },
      "source": [
        "## Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QdsdGwyq1tI"
      },
      "source": [
        "def get_dataset(preprocessor, batch_size):\n",
        "    with tf.device('/job:localhost'):\n",
        "        # batch_size=-1 is a way to load the dataset into memory\n",
        "        in_memory_ds = tfds.load(\"kornli\", batch_size=-1, shuffle_files=True)\n",
        "\n",
        "    tfds_info = tfds.builder(\"kornli\").info\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(in_memory_ds['mnli_train'])\n",
        "    dev_ds = tf.data.Dataset.from_tensor_slices(in_memory_ds['xnli_dev'])\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(in_memory_ds['xnli_test'])\n",
        "    num_examples = tfds_info.splits['mnli_train'].num_examples\n",
        "\n",
        "    train_ds = (\n",
        "        train_ds\n",
        "        .shuffle(num_examples, reshuffle_each_iteration=True)\n",
        "        .batch(batch_size, drop_remainder=True)\n",
        "        .map(lambda x: (preprocessor([x['sentence1'], x['sentence2']]), x['gold_label']), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    )\n",
        "    dev_ds = (\n",
        "        dev_ds\n",
        "        .batch(batch_size)\n",
        "        .map(lambda x: (preprocessor([x['sentence1'], x['sentence2']]), x['gold_label']), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    )\n",
        "    test_ds = (\n",
        "        test_ds\n",
        "        .batch(batch_size)\n",
        "        .map(lambda x: (preprocessor([x['sentence1'], x['sentence2']]), x['gold_label']), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    )\n",
        "    return (train_ds, dev_ds, test_ds), num_examples"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ftxKDfSu8hZ"
      },
      "source": [
        "## Run train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-ztTKdVq5CU",
        "outputId": "610d9681-625e-4203-f853-6584d450fb20"
      },
      "source": [
        "preprocessor = create_preprocessing_model()\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    (train_ds, dev_ds, test_ds), num_examples = get_dataset(preprocessor, BATCH_SIZE)\n",
        "    print(\"Element spec:\", train_ds.element_spec)\n",
        "    print(\"Num examples:\", num_examples)\n",
        "    steps_per_epoch = math.ceil(num_examples / BATCH_SIZE)\n",
        "    print(\"steps per epoch:\", steps_per_epoch)\n",
        "    num_train_steps = steps_per_epoch * EPOCHS\n",
        "    print(\"total num steps:\", num_train_steps)\n",
        "\n",
        "    model = create_model()\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=BertScheduler(LEARNING_RATE, WARMUP_RATE, num_train_steps)),\n",
        "        metrics=['acc']\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=dev_ds,\n",
        "    )\n",
        "    model.evaluate(test_ds)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element spec: ({'input_word_ids': TensorSpec(shape=(64, 128), dtype=tf.int32, name=None), 'input_mask': TensorSpec(shape=(64, 128), dtype=tf.int32, name=None)}, TensorSpec(shape=(64,), dtype=tf.int64, name=None))\n",
            "Num examples: 392702\n",
            "steps per epoch: 6136\n",
            "total num steps: 30680\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_mask (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_word_ids (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)     {'encoder_outputs':  27803904    ['input_mask[0][0]',             \n",
            "                                 [(None, None, 768)               'input_word_ids[0][0]']         \n",
            "                                , (None, None, 768)                                               \n",
            "                                , (None, None, 768)                                               \n",
            "                                ],                                                                \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, None, 768),                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_2[0][3]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            2307        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 27,806,211\n",
            "Trainable params: 27,806,211\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/PartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"Adam/gradients/PartitionedCall:0\", shape=(None, 768), dtype=float32), dense_shape=Tensor(\"Adam/gradients/PartitionedCall:2\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6135/6135 [==============================] - 241s 34ms/step - loss: 0.8863 - acc: 0.5851 - val_loss: 0.7750 - val_acc: 0.6590\n",
            "Epoch 2/5\n",
            "6135/6135 [==============================] - 206s 33ms/step - loss: 0.7427 - acc: 0.6772 - val_loss: 0.7173 - val_acc: 0.6948\n",
            "Epoch 3/5\n",
            "6135/6135 [==============================] - 206s 34ms/step - loss: 0.6791 - acc: 0.7113 - val_loss: 0.7332 - val_acc: 0.6956\n",
            "Epoch 4/5\n",
            "6135/6135 [==============================] - 205s 33ms/step - loss: 0.6312 - acc: 0.7355 - val_loss: 0.7338 - val_acc: 0.6888\n",
            "Epoch 5/5\n",
            "6135/6135 [==============================] - 205s 33ms/step - loss: 0.5951 - acc: 0.7532 - val_loss: 0.7392 - val_acc: 0.6908\n",
            "79/79 [==============================] - 8s 49ms/step - loss: 0.7220 - acc: 0.7062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8TVAYm4u-LP"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksg4gOagrBo_",
        "outputId": "dd58e3e7-8f08-47a7-e37d-4a58ceadc5bf"
      },
      "source": [
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "model.save(\"distilkobert_kornli\", include_optimizer=False, options=save_options)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 225). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: distilkobert_kornli/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: distilkobert_kornli/assets\n"
          ]
        }
      ]
    }
  ]
}